{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f331929-4e07-4321-8dde-b5847b9b3621",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-16 19:38:24.499690: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-01-16 19:38:23.636783: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-01-16 19:38:23.642586: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2026-01-16 19:38:23.642611: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2026-01-16 19:38:25.295942: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2026-01-16 19:38:25.296071: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2026-01-16 19:38:25.296083: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "from waymo_open_dataset import dataset_pb2 as open_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17d62cc5-c62d-49b2-bd8a-7ef645d9cefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Paths Ready\n"
     ]
    }
   ],
   "source": [
    "TRAIN_TFRECORD = \"/home/kakani/waymo_project/1_data/tfrecords/training\"\n",
    "VAL_TFRECORD   = \"/home/kakani/waymo_project/1_data/tfrecords/validation\"\n",
    "\n",
    "RAW_IMG_OUT = \"/home/kakani/waymo_project/1_data/extracted/images_raw\"\n",
    "RAW_LBL_OUT = \"/home/kakani/waymo_project/1_data/extracted/labels_raw\"\n",
    "\n",
    "os.makedirs(RAW_IMG_OUT, exist_ok=True)\n",
    "os.makedirs(RAW_LBL_OUT, exist_ok=True)\n",
    "\n",
    "print(\"✅ Paths Ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c528c163-bc33-4e3c-aa36-ae86d53df8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ TRAIN_FILE: /home/kakani/waymo_project/1_data/tfrecords/training/segment-10017090168044687777_6380_000_6400_000_with_camera_labels.tfrecord\n",
      "✅ VAL_FILE: /home/kakani/waymo_project/1_data/tfrecords/validation/segment-10203656353524179475_7625_000_7645_000_with_camera_labels.tfrecord\n"
     ]
    }
   ],
   "source": [
    "train_files = sorted([os.path.join(TRAIN_TFRECORD, f) for f in os.listdir(TRAIN_TFRECORD) if f.endswith(\".tfrecord\")])\n",
    "val_files   = sorted([os.path.join(VAL_TFRECORD, f) for f in os.listdir(VAL_TFRECORD) if f.endswith(\".tfrecord\")])\n",
    "\n",
    "TRAIN_FILE = train_files[0]\n",
    "VAL_FILE   = val_files[0]\n",
    "\n",
    "print(\"✅ TRAIN_FILE:\", TRAIN_FILE)\n",
    "print(\"✅ VAL_FILE:\", VAL_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "075814ea-b9d2-4e59-afa0-18bd9bbbaeb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Label map ready\n"
     ]
    }
   ],
   "source": [
    "WAYMO_TO_YOLO = {\n",
    "    1: 0,   # Vehicle\n",
    "    2: 1,   # Pedestrian\n",
    "    3: 2,   # Sign\n",
    "    4: 3    # Cyclist\n",
    "}\n",
    "\n",
    "YOLO_CLASS_NAMES = {\n",
    "    0: \"VEHICLE\",\n",
    "    1: \"PEDESTRIAN\",\n",
    "    2: \"SIGN\",\n",
    "    3: \"CYCLIST\"\n",
    "}\n",
    "print(\"✅ Label map ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "188df180-5a9b-435c-a03f-f83892faa0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_yolo_label(txt_path, labels):\n",
    "    with open(txt_path, \"w\") as f:\n",
    "        for row in labels:\n",
    "            f.write(\" \".join(map(str, row)) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d95ccf6b-111e-478d-8986-6debd8bca30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_tfrecord(tfrecord_path, prefix, max_frames=20):\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_path, compression_type='')\n",
    "\n",
    "    records = []\n",
    "    frame_id = 0\n",
    "\n",
    "    for data in tqdm(dataset.take(max_frames), desc=f\"Extracting {prefix}\"):\n",
    "        frame = open_dataset.Frame()\n",
    "        frame.ParseFromString(bytearray(data.numpy()))\n",
    "\n",
    "        # only FRONT camera\n",
    "        target_camera = open_dataset.CameraName.FRONT\n",
    "\n",
    "        front_img = None\n",
    "        for img in frame.images:\n",
    "            if img.name == target_camera:\n",
    "                front_img = img\n",
    "                break\n",
    "\n",
    "        if front_img is None:\n",
    "            continue\n",
    "\n",
    "        # decode image using OpenCV\n",
    "        img_np = np.frombuffer(front_img.image, np.uint8)\n",
    "        img_cv = cv2.imdecode(img_np, cv2.IMREAD_COLOR)\n",
    "\n",
    "        if img_cv is None:\n",
    "            continue\n",
    "\n",
    "        h, w, _ = img_cv.shape\n",
    "\n",
    "        # output filenames\n",
    "        img_name = f\"{prefix}_frame_{frame_id:04d}.jpg\"\n",
    "        lbl_name = f\"{prefix}_frame_{frame_id:04d}.txt\"\n",
    "\n",
    "        img_path = os.path.join(RAW_IMG_OUT, img_name)\n",
    "        lbl_path = os.path.join(RAW_LBL_OUT, lbl_name)\n",
    "\n",
    "        cv2.imwrite(img_path, img_cv)\n",
    "\n",
    "        # Extract labels\n",
    "        yolo_labels = []\n",
    "        for cam_lbl in frame.camera_labels:\n",
    "            if cam_lbl.name == target_camera:\n",
    "                for label in cam_lbl.labels:\n",
    "                    if label.type not in WAYMO_TO_YOLO:\n",
    "                        continue\n",
    "\n",
    "                    cls = WAYMO_TO_YOLO[label.type]\n",
    "                    box = label.box\n",
    "\n",
    "                    # Waymo box coords\n",
    "                    cx, cy = box.center_x, box.center_y\n",
    "                    bw, bh = box.length, box.width\n",
    "\n",
    "                    # YOLO normalize\n",
    "                    x = cx / w\n",
    "                    y = cy / h\n",
    "                    bw_n = bw / w\n",
    "                    bh_n = bh / h\n",
    "\n",
    "                    yolo_labels.append([cls, x, y, bw_n, bh_n])\n",
    "\n",
    "                    # for CSV\n",
    "                    records.append([img_name, YOLO_CLASS_NAMES[cls], cx-bw/2, cy-bh/2, cx+bw/2, cy+bh/2])\n",
    "\n",
    "        save_yolo_label(lbl_path, yolo_labels)\n",
    "\n",
    "        print(f\"✅ Saved {img_name} + {lbl_name} | boxes={len(yolo_labels)}\")\n",
    "        frame_id += 1\n",
    "\n",
    "    return records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae31532a-2e91-4b8c-acf7-f2a46824cfb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-16 19:39:46.805646: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-01-16 19:39:46.805923: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/kakani/waymo310/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2026-01-16 19:39:46.806024: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/kakani/waymo310/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2026-01-16 19:39:46.806104: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/kakani/waymo310/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2026-01-16 19:39:46.806182: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/kakani/waymo310/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2026-01-16 19:39:46.806259: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/kakani/waymo310/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2026-01-16 19:39:46.806335: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/kakani/waymo310/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2026-01-16 19:39:46.806410: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/kakani/waymo310/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2026-01-16 19:39:46.806487: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/kakani/waymo310/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2026-01-16 19:39:46.806505: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2026-01-16 19:39:46.807676: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Extracting train: 3it [00:00,  9.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved train_frame_0000.jpg + train_frame_0000.txt | boxes=5\n",
      "✅ Saved train_frame_0001.jpg + train_frame_0001.txt | boxes=5\n",
      "✅ Saved train_frame_0002.jpg + train_frame_0002.txt | boxes=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting train: 5it [00:00, 11.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved train_frame_0003.jpg + train_frame_0003.txt | boxes=7\n",
      "✅ Saved train_frame_0004.jpg + train_frame_0004.txt | boxes=7\n",
      "✅ Saved train_frame_0005.jpg + train_frame_0005.txt | boxes=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting train: 9it [00:00, 12.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved train_frame_0006.jpg + train_frame_0006.txt | boxes=7\n",
      "✅ Saved train_frame_0007.jpg + train_frame_0007.txt | boxes=9\n",
      "✅ Saved train_frame_0008.jpg + train_frame_0008.txt | boxes=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting train: 11it [00:00, 12.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved train_frame_0009.jpg + train_frame_0009.txt | boxes=10\n",
      "✅ Saved train_frame_0010.jpg + train_frame_0010.txt | boxes=11\n",
      "✅ Saved train_frame_0011.jpg + train_frame_0011.txt | boxes=11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting train: 15it [00:01, 13.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved train_frame_0012.jpg + train_frame_0012.txt | boxes=11\n",
      "✅ Saved train_frame_0013.jpg + train_frame_0013.txt | boxes=10\n",
      "✅ Saved train_frame_0014.jpg + train_frame_0014.txt | boxes=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting train: 17it [00:01, 13.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved train_frame_0015.jpg + train_frame_0015.txt | boxes=5\n",
      "✅ Saved train_frame_0016.jpg + train_frame_0016.txt | boxes=4\n",
      "✅ Saved train_frame_0017.jpg + train_frame_0017.txt | boxes=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting train: 21it [00:01, 13.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved train_frame_0018.jpg + train_frame_0018.txt | boxes=4\n",
      "✅ Saved train_frame_0019.jpg + train_frame_0019.txt | boxes=4\n",
      "✅ Saved train_frame_0020.jpg + train_frame_0020.txt | boxes=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting train: 23it [00:01, 13.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved train_frame_0021.jpg + train_frame_0021.txt | boxes=4\n",
      "✅ Saved train_frame_0022.jpg + train_frame_0022.txt | boxes=4\n",
      "✅ Saved train_frame_0023.jpg + train_frame_0023.txt | boxes=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting train: 27it [00:02, 13.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved train_frame_0024.jpg + train_frame_0024.txt | boxes=4\n",
      "✅ Saved train_frame_0025.jpg + train_frame_0025.txt | boxes=4\n",
      "✅ Saved train_frame_0026.jpg + train_frame_0026.txt | boxes=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting train: 30it [00:02, 13.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved train_frame_0027.jpg + train_frame_0027.txt | boxes=5\n",
      "✅ Saved train_frame_0028.jpg + train_frame_0028.txt | boxes=4\n",
      "✅ Saved train_frame_0029.jpg + train_frame_0029.txt | boxes=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting val: 3it [00:00, 12.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved val_frame_0000.jpg + val_frame_0000.txt | boxes=23\n",
      "✅ Saved val_frame_0001.jpg + val_frame_0001.txt | boxes=24\n",
      "✅ Saved val_frame_0002.jpg + val_frame_0002.txt | boxes=23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting val: 7it [00:00, 14.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved val_frame_0003.jpg + val_frame_0003.txt | boxes=25\n",
      "✅ Saved val_frame_0004.jpg + val_frame_0004.txt | boxes=25\n",
      "✅ Saved val_frame_0005.jpg + val_frame_0005.txt | boxes=25\n",
      "✅ Saved val_frame_0006.jpg + val_frame_0006.txt | boxes=24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting val: 9it [00:00, 14.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved val_frame_0007.jpg + val_frame_0007.txt | boxes=24\n",
      "✅ Saved val_frame_0008.jpg + val_frame_0008.txt | boxes=25\n",
      "✅ Saved val_frame_0009.jpg + val_frame_0009.txt | boxes=25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting val: 13it [00:00, 14.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved val_frame_0010.jpg + val_frame_0010.txt | boxes=25\n",
      "✅ Saved val_frame_0011.jpg + val_frame_0011.txt | boxes=24\n",
      "✅ Saved val_frame_0012.jpg + val_frame_0012.txt | boxes=24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting val: 17it [00:01, 14.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved val_frame_0013.jpg + val_frame_0013.txt | boxes=25\n",
      "✅ Saved val_frame_0014.jpg + val_frame_0014.txt | boxes=26\n",
      "✅ Saved val_frame_0015.jpg + val_frame_0015.txt | boxes=26\n",
      "✅ Saved val_frame_0016.jpg + val_frame_0016.txt | boxes=26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting val: 20it [00:01, 14.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved val_frame_0017.jpg + val_frame_0017.txt | boxes=25\n",
      "✅ Saved val_frame_0018.jpg + val_frame_0018.txt | boxes=24\n",
      "✅ Saved val_frame_0019.jpg + val_frame_0019.txt | boxes=24\n",
      "✅ Extraction completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_records = extract_from_tfrecord(TRAIN_FILE, \"train\", max_frames=30)\n",
    "val_records   = extract_from_tfrecord(VAL_FILE, \"val\", max_frames=20)\n",
    "\n",
    "print(\"✅ Extraction completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8517c0a-eb24-4142-ab5b-3b24580cfa2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CSV saved: /home/kakani/waymo_project/1_data/extracted/annotations.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_frame_0000.jpg</td>\n",
       "      <td>VEHICLE</td>\n",
       "      <td>1346.234085</td>\n",
       "      <td>437.691870</td>\n",
       "      <td>1586.869875</td>\n",
       "      <td>547.588530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_frame_0000.jpg</td>\n",
       "      <td>VEHICLE</td>\n",
       "      <td>1019.702055</td>\n",
       "      <td>458.850135</td>\n",
       "      <td>1198.442025</td>\n",
       "      <td>614.852865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_frame_0000.jpg</td>\n",
       "      <td>VEHICLE</td>\n",
       "      <td>1150.756980</td>\n",
       "      <td>471.481935</td>\n",
       "      <td>1212.652800</td>\n",
       "      <td>566.852025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_frame_0000.jpg</td>\n",
       "      <td>VEHICLE</td>\n",
       "      <td>991.912095</td>\n",
       "      <td>467.376600</td>\n",
       "      <td>1020.333645</td>\n",
       "      <td>506.535180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_frame_0000.jpg</td>\n",
       "      <td>VEHICLE</td>\n",
       "      <td>1199.389410</td>\n",
       "      <td>540.009450</td>\n",
       "      <td>1560.658890</td>\n",
       "      <td>667.590630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  image    class         xmin        ymin         xmax  \\\n",
       "0  train_frame_0000.jpg  VEHICLE  1346.234085  437.691870  1586.869875   \n",
       "1  train_frame_0000.jpg  VEHICLE  1019.702055  458.850135  1198.442025   \n",
       "2  train_frame_0000.jpg  VEHICLE  1150.756980  471.481935  1212.652800   \n",
       "3  train_frame_0000.jpg  VEHICLE   991.912095  467.376600  1020.333645   \n",
       "4  train_frame_0000.jpg  VEHICLE  1199.389410  540.009450  1560.658890   \n",
       "\n",
       "         ymax  \n",
       "0  547.588530  \n",
       "1  614.852865  \n",
       "2  566.852025  \n",
       "3  506.535180  \n",
       "4  667.590630  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(train_records + val_records,\n",
    "                  columns=[\"image\",\"class\",\"xmin\",\"ymin\",\"xmax\",\"ymax\"])\n",
    "\n",
    "csv_path = \"/home/kakani/waymo_project/1_data/extracted/annotations.csv\"\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(\"✅ CSV saved:\", csv_path)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "828d5fb1-e79b-4fbc-9dd4-868f5587237d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 images\n",
      "50 labels\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir(RAW_IMG_OUT)), \"images\")\n",
    "print(len(os.listdir(RAW_LBL_OUT)), \"labels\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a048a3bd-a29f-4054-9f05-e1b35cd51066",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
